<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1. Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance（Data Mixture）Motivation Challenge: 现有的data mixing方法基于heuristics，没有一个明确的标准去决定“是否是好的mixing” 要决定一个好的mixing，需要跑整个的">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes (warning: contains Chinese)">
<meta property="og:url" content="http://example.com/2024/11/29/Notes/index.html">
<meta property="og:site_name" content="DizzyHardSugar&#39;s Blog">
<meta property="og:description" content="1. Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance（Data Mixture）Motivation Challenge: 现有的data mixing方法基于heuristics，没有一个明确的标准去决定“是否是好的mixing” 要决定一个好的mixing，需要跑整个的">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-11-28T13:00:00.000Z">
<meta property="article:modified_time" content="2024-11-29T10:48:53.402Z">
<meta property="article:author" content="DizzyHardSugar">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2024/11/29/Notes/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Notes (warning: contains Chinese) | DizzyHardSugar's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">DizzyHardSugar's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/11/29/Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="DizzyHardSugar">
      <meta itemprop="description" content="notes, thoughts">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DizzyHardSugar's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Notes (warning: contains Chinese)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2024-11-29 00:00:00 / Modified: 21:48:53" itemprop="dateCreated datePublished" datetime="2024-11-29T00:00:00+11:00">2024-11-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-Data-Mixing-Laws-Optimizing-Data-Mixtures-by-Predicting-Language-Modeling-Performance（Data-Mixture）"><a href="#1-Data-Mixing-Laws-Optimizing-Data-Mixtures-by-Predicting-Language-Modeling-Performance（Data-Mixture）" class="headerlink" title="1. Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance（Data Mixture）"></a>1. Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance（Data Mixture）</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul>
<li><strong>Challenge</strong>:<ul>
<li>现有的data mixing方法基于heuristics，没有一个明确的标准去决定“是否是好的mixing”</li>
<li>要决定一个好的mixing，需要跑整个的训练过程，昂贵和耗时间并且在计算上prohibitive</li>
</ul>
</li>
<li><strong>Goal</strong>:<ul>
<li>一个predictive framework：能在训练前在多种数据混合上估计模型的表现</li>
<li>能够使得data mixture的优化效率更高</li>
<li>能获得对大模型&#x2F;大型数据集的表现估计</li>
</ul>
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>在预训练阶段，语言模型 pθ的目标函数，即基于给定训练数据的<strong>负对数似然</strong>，<br>![[Pasted image 20241123030144.png]]<br>![[Pasted image 20241123030205.png]]</p>
<ul>
<li><strong>Data Mixing Laws</strong>: $$L_i​(r_1​,…,r_M​)&#x3D;c_i​+k_i​exp(\Sigma_{j&#x3D;1}^M ​t_{ij}​r_j​)$$ 其中$r_j$是domain j的占比，$c_i,k_i,t_{ij}$是要去fit的参数。通过fitting这个函数到观察到的 采样数据混合上的模型表现，这些参数能够在不完全训练的情况下，在不可见的数据混合上预测validation loss</li>
<li><strong>Nested Scaling Laws</strong>: <ul>
<li>(Existing) <strong>Scaling laws</strong>: 描述ML模型的表现随着几个key variables变化，例如：Model Size, Dataset Size, Compute budget</li>
<li>(1) Power-Law Decay of Loss with Model Size: $L(N)&#x3D;aN^{−b}+c$，N是参数数量，</li>
<li>(2) Power-Law Scaling with Dataset Size: $L(D)&#x3D;aD^{−b}+c$，D是训练数据集的大小，（注意，大数据集-&gt;更小的loss，但是improvement会逐渐减小随着dataset的size增大）</li>
<li>(3) Interdependence of Model Size and Dataset Size:<ul>
<li>Undersized models underfit large datasets.</li>
<li>Oversized models overfit small datasets and fail to generalize.</li>
</ul>
</li>
<li>(4) Compute-Optimal Scaling: Compute budget C: $C∼N^{0.7}D^{0.4}T^{0.9}$</li>
<li>论文的<strong>Nested Scaling Laws</strong>是结合data mixing laws和现有的scaling laws，for：Training steps and Model size. -&gt; 预测在巨大数据集上的大模型表现，只基于小规模试验。</li>
</ul>
</li>
<li><strong>Dynamic Data Scheduling</strong>:<ul>
<li>扩展framework到continual learning，预测重要的数据混合，用来避免catastrophic forgetting（模型在增长的训练中忘记原来的knowledge）</li>
</ul>
</li>
<li>评估： <ul>
<li>在小规模实验中拟合的混合比例-损失模型可以准确预测大规模实验中各种混合比例的验证损失。</li>
<li>实验表明，即便规模变化（例如训练数据增大或模型变大），这种指数型函数关系依然具有较强的泛化能力。</li>
<li>效果：在RedPajama上（1B model，在100B tokens上训练），<ul>
<li>模型用优化后的混合训练，能够达到与比它们训练48%更长的模型可比的表现</li>
<li>预测能够和不同的数据混合、训练config相符合</li>
</ul>
</li>
</ul>
</li>
<li>思路：<ol>
<li>pilot study: 先由2 domain的损失得到一个损失函数，</li>
<li>扩展到2个以上domain的情况，假设兼容性（compatibility）和对称性(symmetry)，兼容性：如果M&#x3D;2则为pilot study里得到的式子；对称性：任何交换都不会改变函数形式</li>
<li>假设四个拟合函数，试验观测拟合效果，发现1和4都可靠，但是4的参数更少，选取4.</li>
<li>预测任何验证混合：显示的（explicit）直接使用该函数建模；隐式的（implicit）：假设有K个隐式domain，先直接训练，然后对于假定的K再训练去fit所有参数，根据fit到的参数计算损失，比较Absolute Errors，发现K需要&gt;&#x3D;实际的domain数量</li>
</ol>
</li>
</ul>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>模型表现提升、预测准确性可靠，展现出dynamic data schedules的潜力，减少了灾难性遗忘的影响（continual learning可持续性学习）</p>
<h2 id="Weakness"><a href="#Weakness" class="headerlink" title="Weakness"></a>Weakness</h2><p>(1) exp函数太具体，虽然在实验中确实effective，但是它的在更复杂或者种类更多的数据集上的泛用性（generalizability）不明确<br>(2) 对multi-task的训练场景只有limited exploration<br>(3) Interpretability: 没有详细解说为什么某些mixture更好（domain之间的联系）<br>(4) real-world scalability: 在工业规模的数据集上预测数据混合表现将面临挑战，因为更高的复杂度和噪声。</p>
<h1 id="2-REGMIX-Data-Mixture-as-Regression-for-Language-Model-Pre-training-Data-Mixture"><a href="#2-REGMIX-Data-Mixture-as-Regression-for-Language-Model-Pre-training-Data-Mixture" class="headerlink" title="2. REGMIX: Data Mixture as Regression for Language Model Pre-training(Data Mixture)"></a>2. REGMIX: Data Mixture as Regression for Language Model Pre-training(Data Mixture)</h1><h2 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h2><p>大语言模型的性能很大程度上取决于训练数据的mixture，现有的优化方法存在以下问题：</p>
<ol>
<li>数据选择的复杂性</li>
<li>人工数据选择的局限性</li>
<li>现有方法的计算成本高昂：比如DoReMi算法，需要在大规模模型和完整数据集上反复训练，计算开销大<br>问题：如何以低成本和高效率找到一个最好的数据配比<br><strong>核心假设</strong>：数据配比的秩不变性(Rank Invariance)，不同数据配比对模型性能的影响在小模型和大模型之间保持一致，小模型的训练结果可以用来预测大模型的最佳数据配比。</li>
</ol>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><p>把数据配比优化问题，形式化为回归任务</p>
<ol>
<li>小规模代理模型训练（small proxy models)：生成多种随机数据配比（例如使用Dirichlet分布），并在小规模代理模型(1M参数，1B训练token)上进行训练</li>
<li>拟合回归模型：用代理模型的训练结果建立一个回归模型，将数据配比作为特征（features），目标变量即回归模型用于拟合的数据中的输出值（比如小规模代理模型在验证机上的损失值）作为标签（labels）（标签：监督学习中用来指导模型学习的真实值，实际上与目标变量在语义上一致，代表需要预测的值）</li>
<li>模拟并预测最佳数据配比：利用训练好的回归模型，在更大范围的潜在数据配比中进行预测，从中找到性能最佳的配比</li>
<li>大规模模型训练：将预测的最佳数据配比应用于大规模模型训练（例如1B参数，25B token）进行训练，并验证其效果</li>
</ol>
<h2 id="Results-1"><a href="#Results-1" class="headerlink" title="Results"></a>Results</h2><p>论文的实验验证了REGMIX的有效性：</p>
<ol>
<li>数据配比影响显著：数据配比对下游任务性能影响巨大，例如在lambada任务（检测模型对上下文语境的理解和生成能力）中，最优模型比最差模型性能提升高达14.6%</li>
<li>秩不变性验证：小模型（1M参数，1B token）和大模型（1B参数，25B token）的数据配比排名之间Spearman相关性达到97.12%，验证了秩不变性假设。![[Pasted image 20241123225652.png]] <strong>为什么使用Spearman相关性</strong>：为了验证 “秩不变性” 假设，即 <strong>数据配比对模型性能影响的相对排名在小模型和大模型之间是一致的</strong>。在这个研究中，不需要小模型和大模型的验证损失绝对值完全一致，而是关注<strong>数据配比对性能的影响趋势是否一致</strong>（即排名一致性）；Spearman相关性适用于测量这种单调关系，而不是要求严格的线性关系。<strong>数据配比对小模型的影响趋势</strong>与<strong>对大模型的影响趋势</strong>一致。</li>
<li>优于DoReMi和人工选择：REGMIX在多个任务上性能超过DoReMi，计算成本只是DoReMi的10%</li>
<li>下游任务性能提升：在HellaSwag、COPA等下游任务中，REGMIX实现了最优性能。</li>
</ol>
<h3 id="Weakness-1"><a href="#Weakness-1" class="headerlink" title="Weakness"></a>Weakness</h3><ul>
<li><strong>秩不变性假设的限制</strong>：虽然实验验证了秩不变性，但在更多领域或更大规模的数据上，其稳定性仍需进一步研究。</li>
<li><strong>回归模型的复杂性</strong>：回归模型的效果依赖于代理模型训练的质量，若数据配比的覆盖面不足，可能影响预测的准确性。</li>
<li><strong>不支持动态调整</strong>：REGMIX在训练前就固定了数据配比，无法根据训练动态调整数据权重，可能在某些情况下表现受限。</li>
<li><strong>只关注验证损失</strong>：主要以验证集损失作为目标，未对其他可能的优化目标（如下游任务性能、鲁棒性）进行探索。</li>
</ul>
<h1 id="3-SELP-A-Semantically-Driven-Approach-for-Separated-and-Accurate-Class-Prototypes-in-Few-Shot-Text-Classification"><a href="#3-SELP-A-Semantically-Driven-Approach-for-Separated-and-Accurate-Class-Prototypes-in-Few-Shot-Text-Classification" class="headerlink" title="3. SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification"></a>3. SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification</h1><h2 id="Meta-learning"><a href="#Meta-learning" class="headerlink" title="Meta-learning"></a>Meta-learning</h2><p><strong>Meta-learning</strong>（元学习）是一种机器学习方法，旨在让模型通过学习如何“学习”来更快地适应新任务。简单来说，它训练模型在面对新任务时能高效利用少量数据进行泛化。<strong>元学习</strong>在少样本学习（Few-shot Learning）中尤为重要，因为它帮助模型从有限的数据中快速捕获任务特性。</p>
<hr>
<h3 id="1-Meta-learning-的基本概念"><a href="#1-Meta-learning-的基本概念" class="headerlink" title="1. Meta-learning 的基本概念"></a><strong>1. Meta-learning 的基本概念</strong></h3><p>Meta-learning 不直接学习具体的任务，而是从多个任务中总结出一种学习的能力。核心思想是：</p>
<blockquote>
<p><strong>“不是学习数据本身，而是学习如何从数据中学习。”</strong></p>
</blockquote>
<p>在 Few-shot Text Classification 中，Meta-learning 通过模拟少样本任务（Few-shot Tasks）训练模型，使其能从少量示例中快速适应新的分类任务。</p>
<hr>
<h3 id="2-Meta-learning-的关键组成部分"><a href="#2-Meta-learning-的关键组成部分" class="headerlink" title="2. Meta-learning 的关键组成部分"></a><strong>2. Meta-learning 的关键组成部分</strong></h3><p>Meta-learning 通常涉及以下三个关键组成部分：</p>
<h4 id="1-Meta-learner"><a href="#1-Meta-learner" class="headerlink" title="(1) Meta-learner"></a><strong>(1) Meta-learner</strong></h4><ul>
<li>Meta-learner 是元学习的核心模型，负责从多个任务中提取通用的学习策略。</li>
<li><strong>目标</strong>：学习一种高效的学习方式，能快速适应新任务。</li>
</ul>
<h4 id="2-Base-learner"><a href="#2-Base-learner" class="headerlink" title="(2) Base-learner"></a><strong>(2) Base-learner</strong></h4><ul>
<li>Base-learner 是任务级别的学习模型，用于处理具体任务。</li>
<li><strong>目标</strong>：在 Meta-learner 的指导下，利用少量数据解决具体任务（如 Few-shot Text Classification）。</li>
</ul>
<h4 id="3-Task-Distribution"><a href="#3-Task-Distribution" class="headerlink" title="(3) Task Distribution"></a><strong>(3) Task Distribution</strong></h4><ul>
<li>Meta-learning 通过大量任务（Task）进行训练。</li>
<li>每个任务通常包含：<ul>
<li><strong>支持集（Support Set）</strong>：用于训练 Base-learner 的少量样本。</li>
<li><strong>查询集（Query Set）</strong>：用于评估 Base-learner 在新任务上的表现。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-Meta-learning-的主要方法"><a href="#3-Meta-learning-的主要方法" class="headerlink" title="3. Meta-learning 的主要方法"></a><strong>3. Meta-learning 的主要方法</strong></h3><p>Meta-learning 通常可以分为三大类方法：</p>
<h4 id="1-基于优化的-Meta-learning"><a href="#1-基于优化的-Meta-learning" class="headerlink" title="(1) 基于优化的 Meta-learning"></a><strong>(1) 基于优化的 Meta-learning</strong></h4><ul>
<li><strong>代表方法</strong>：MAML（Model-Agnostic Meta-Learning）。</li>
<li><strong>原理</strong>：<ul>
<li>学习一个初始模型参数，使得模型能通过少量梯度更新快速适应新任务。</li>
<li>在训练过程中，每个任务都进行独立的优化，通过元更新让模型找到一个对所有任务都适用的初始参数。</li>
</ul>
</li>
<li><strong>应用于 Few-shot Text Classification</strong>：<ul>
<li>模型能通过少量支持集样本快速调整参数，从而适应新分类任务。</li>
</ul>
</li>
</ul>
<h4 id="2-基于模型的-Meta-learning"><a href="#2-基于模型的-Meta-learning" class="headerlink" title="(2) 基于模型的 Meta-learning"></a><strong>(2) 基于模型的 Meta-learning</strong></h4><ul>
<li><strong>代表方法</strong>：MANN（Memory-Augmented Neural Networks）。</li>
<li><strong>原理</strong>：<ul>
<li>构建一个具有快速学习能力的特殊模型架构，如记忆增强网络。</li>
<li>模型通过外部记忆模块，直接从支持集中提取特征并生成分类结果。</li>
</ul>
</li>
<li><strong>应用于 Few-shot Text Classification</strong>：<ul>
<li>模型可以记忆支持集中每个类别的特征，并直接匹配查询集中的新样本。</li>
</ul>
</li>
</ul>
<h4 id="3-基于度量的-Meta-learning"><a href="#3-基于度量的-Meta-learning" class="headerlink" title="(3) 基于度量的 Meta-learning"></a><strong>(3) 基于度量的 Meta-learning</strong></h4><ul>
<li><strong>代表方法</strong>：Prototypical Networks。</li>
<li><strong>原理</strong>：<ul>
<li>通过度量学习（Metric Learning）将少样本任务转化为几何空间中的距离问题。</li>
<li>为每个类别生成一个“原型向量”，根据查询样本与原型的距离进行分类。</li>
</ul>
</li>
<li><strong>应用于 Few-shot Text Classification</strong>：<ul>
<li>将每个类别的支持集样本嵌入到向量空间中，计算类别中心，然后将查询样本分配到距离最近的类别。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-Meta-learning-的优势"><a href="#4-Meta-learning-的优势" class="headerlink" title="4. Meta-learning 的优势"></a><strong>4. Meta-learning 的优势</strong></h3><ol>
<li><strong>快速适应新任务</strong>：<ul>
<li>通过模拟少样本任务训练，模型能在遇到新任务时迅速学习。</li>
</ul>
</li>
<li><strong>适应少样本场景</strong>：<ul>
<li>在数据稀缺的情况下，模型可以利用少量标注数据完成任务。</li>
</ul>
</li>
<li><strong>领域泛化性强</strong>：<ul>
<li>Meta-learning 模型可以在不同任务之间迁移，比如从意图识别任务迁移到情感分析任务。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-应用于-Few-shot-Text-Classification-的示例"><a href="#5-应用于-Few-shot-Text-Classification-的示例" class="headerlink" title="5. 应用于 Few-shot Text Classification 的示例"></a><strong>5. 应用于 Few-shot Text Classification 的示例</strong></h3><h4 id="Prototypical-Networks-示例"><a href="#Prototypical-Networks-示例" class="headerlink" title="Prototypical Networks 示例"></a><strong>Prototypical Networks 示例</strong></h4><ol>
<li>支持集（Support Set）：<ul>
<li>类别 A：<code>[&quot;The movie was great.&quot;, &quot;Amazing storyline!&quot;]</code></li>
<li>类别 B：<code>[&quot;Terrible acting.&quot;, &quot;Worst experience ever.&quot;]</code></li>
</ul>
</li>
<li>查询集（Query Set）：<ul>
<li><code>[&quot;Fantastic film!&quot;, &quot;Awful dialogue.&quot;]</code></li>
</ul>
</li>
<li><strong>过程</strong>：<ul>
<li>为类别 A 和 B 计算原型向量（Prototypes）。</li>
<li>查询样本根据与原型的距离分配到对应类别。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="6-Meta-learning-的挑战"><a href="#6-Meta-learning-的挑战" class="headerlink" title="6. Meta-learning 的挑战"></a><strong>6. Meta-learning 的挑战</strong></h3><ol>
<li><p><strong>任务分布差异</strong>：</p>
<ul>
<li>元学习依赖于大量任务进行训练，如果新任务与训练任务差异较大，效果会受限。</li>
</ul>
</li>
<li><p><strong>模型复杂性</strong>：</p>
<ul>
<li>训练 Meta-learner 的计算成本较高，模型架构通常也较复杂。</li>
</ul>
</li>
<li><p><strong>过拟合风险</strong>：</p>
<ul>
<li>在少样本任务中，支持集数据有限，容易导致 Base-learner 过拟合。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p><strong>Meta-learning</strong> 是通过从多个任务中学习如何学习的方法，在 Few-shot Text Classification 中非常关键。它的核心是训练模型具备快速泛化的能力，能高效利用少量数据完成新任务。</p>
<h2 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h2><p>大量标注数据的收集是消耗时间和费人力的，无法可数的现实数据domains让获取所有数据不现实，因此促进了few-shot text classification的产生。<br>Fine-tuning based methods把任务变成一种fill in the blank format(Howard and Ruder, 2018; Shen et al., 2021；Li and Liang, 2021; Schick and Schütze, 2021)，会导致对task design要求挑剔并且精确，会导致在现实世界的实用性降低；<br>Data augmentation based methods是想要利用帮助数据(auxiliary data or information)和帮助信息，或增强few-shot datasets，但他们会引入新的噪声数据，这些噪声数据会非常依赖之前的knowledge并且也会导致特征损失。<br>Meta-learning based methods是为了旨在通过学习多个模拟的小任务（episodes），赋予模型快速泛化到新类别的能力。（每个 episode 是一个子任务，通常使用少量样本（Few-shot）进行训练）<br>尽管以上都有好的表现，但是目前的方法还是有一些问题，现有的基于度量学习的方法大多注重扩大类间距离，以增强分类效果，但忽略了类原型与语义类簇之间的高级语义关系；原型的语义空间表示不完整，导致度量空间的泛化能力较差，由于语义信息不足，原型可能无法有效代表其对应类别。<br>这篇论文提出一种利用增强标签语义的方法，校准类原型，生成更加分离且语义准确的原型。改善类内紧凑性和解决过拟合问题，提高模型对新类的泛化能力。</p>
<h2 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h2><ol>
<li><strong>整体框架</strong>：<ul>
<li>使用 <strong>BERT</strong> 作为文本编码器，并通过一个可训练的 <strong>Prompt Pool</strong> 增强标签的语义内容。</li>
<li>利用这些增强的标签来校准类原型，并设计了中心损失（Center Loss）和模拟标签分布（Simulated Label Distribution, SLD）方法来进一步提升分类性能。</li>
</ul>
</li>
<li><strong>关键步骤</strong>：<ul>
<li><strong>Prompt Pool</strong>：<ul>
<li>使用一个由可训练提示（Prompts）组成的池，每个提示与一个可学习的键（Key）相连，动态生成与类别相关的提示。</li>
<li>将提示与类别名结合，生成增强的标签嵌入。</li>
</ul>
</li>
<li><strong>原型校准</strong>：<ul>
<li>初步生成的原型基于支持集样本的均值计算，并通过增强标签进一步校准，以增加语义准确性。</li>
</ul>
</li>
<li><strong>中心损失</strong>：<ul>
<li>定义了一个正则化损失，强制每个样本靠近其所属类的原型，从而增强类内紧凑性。</li>
</ul>
</li>
<li><strong>模拟标签分布</strong>：<ul>
<li>将标签从“硬标签”（one-hot encoding）转换为“软标签”，以捕捉实例与标签之间的关系，并缓解过拟合问题。</li>
</ul>
</li>
</ul>
</li>
<li><strong>模型训练目标</strong>：<ul>
<li>结合中心损失和标签分布损失，使用不确定性权重方法（Uncertainty Weighting）自动调整损失权重。</li>
</ul>
</li>
<li><strong>测试阶段</strong>：<ul>
<li>对于每个测试任务，计算每个标签的提示，生成原型并校准原型，最终通过计算查询样本到原型的距离进行分类。</li>
</ul>
</li>
</ol>
<h2 id="Results-2"><a href="#Results-2" class="headerlink" title="Results"></a>Results</h2><ul>
<li><strong>实验设置</strong>：<ul>
<li>在8个数据集上进行了实验，包括新闻&#x2F;评论分类数据集（如 HuffPost、Amazon）和意图检测数据集（如 Banking77、HWU64）。</li>
<li>使用 5-way 1-shot 和 5-shot 设定，分别评估模型在少样本场景中的性能。</li>
</ul>
</li>
<li><strong>主要结果</strong>：<ul>
<li>SELP 方法在大多数数据集上显著超越了基线方法，特别是在 1-shot 场景下：<ul>
<li>HuffPost 数据集的 1-shot 准确率比最优基线方法提升了 14.2%。</li>
<li>HWU64 数据集的 1-shot 准确率提升了 2.7%。</li>
</ul>
</li>
<li>在长文本和短文本任务中都表现出强大的泛化能力。</li>
</ul>
</li>
<li><strong>可视化分析</strong>：<ul>
<li>使用 t-SNE 可视化了 SELP、ContrastNet 和 TART 的分类效果。</li>
<li>相较其他方法，SELP 显示出更紧密的类内聚合和更清晰的类间边界。</li>
</ul>
</li>
</ul>
<h2 id="Weakness-2"><a href="#Weakness-2" class="headerlink" title="Weakness"></a>Weakness</h2><ul>
<li><strong>模型依赖性</strong>：<ul>
<li>方法依赖于元学习，因此需要至少一个可用的训练任务（Episode）。</li>
<li>实验仅在 <strong>BERT</strong> 模型上进行了评估，未探索其他预训练语言模型（PLMs）的适用性。</li>
</ul>
</li>
<li><strong>文本依赖性</strong>：<ul>
<li>对于过短的文本（如意图检测数据集），方法可能受到信息量不足的限制。</li>
</ul>
</li>
<li><strong>计算复杂性</strong>：<ul>
<li>Prompt Pool 的动态训练和增强标签的校准过程可能带来额外的计算开销。![[Pasted image 20241125025607.png]]</li>
</ul>
</li>
</ul>
<h1 id="4-Hierarchy-aware-Biased-Bound-Margin-Loss-Function-for-Hierarchical-Text-Classification"><a href="#4-Hierarchy-aware-Biased-Bound-Margin-Loss-Function-for-Hierarchical-Text-Classification" class="headerlink" title="4. **Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification"></a>4. **Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification</h1><h2 id="Motivation-3"><a href="#Motivation-3" class="headerlink" title="Motivation"></a>Motivation</h2><p>层次化文本分类（Hierarchical Text Classification, HTC）是一项将文本分类到具有层次结构标签中的任务，目前面临两个关键问题：</p>
<ol>
<li><strong>静态阈值问题</strong>：大多数HTC模型使用固定阈值（如0.5）来判断分类结果，这种方法难以适应数据的动态变化。</li>
<li><strong>标签不平衡问题</strong>：模型倾向于对高频标签过度训练，而对低频标签训练不足，尤其在大规模层次结构中，这种问题更加严重。</li>
</ol>
<p>为了解决上述问题，作者提出了一种新的损失函数——<strong>层次感知偏置边界损失（Hierarchy-aware Biased Bound Margin, HBM）</strong>。</p>
<h1 id="Methods-2"><a href="#Methods-2" class="headerlink" title="Methods"></a>Methods</h1><p>论文的核心是HBM损失函数，改进了现有基于单元（unit-based）的HTC模型。具体包括以下几个关键创新点：</p>
<ol>
<li><p><strong>可学习的边界（Learnable Bounds）</strong>：</p>
<ul>
<li>对于每个单元，动态优化一个边界 tUt_UtU​，使模型能够适应不同单元的特性。</li>
<li>在训练中，边界用于区分正负标签，优化后可在推断阶段作为动态阈值。</li>
</ul>
</li>
<li><p><strong>偏置（Biases）</strong>：</p>
<ul>
<li>在正标签和负标签的边界上加入偏置（bpos,bnegb_{pos}, b_{neg}bpos​,bneg​），使模型对低置信度标签（未充分训练的标签）更加敏感。</li>
<li>偏置通过标签的logits（模型输出值）的标准差计算，高标准差表示模型对标签的训练不足，从而赋予更大的偏置值。</li>
</ul>
</li>
<li><p><strong>边距（Margin）</strong>：</p>
<ul>
<li>在计算损失前，通过边距排除高置信度标签（过度训练的标签），减少其在损失中的影响。</li>
</ul>
<p> <strong>公式</strong>：</p>
<p> ![[Pasted image 20241126005806.png]]</p>
<ul>
<li>$t_U$​: 每个单元的可学习边界。</li>
<li>$b_{pos}^U, b_{neg}^U$: 正、负标签的偏置。</li>
<li>$N_{pos}’^U, N_{neg}’^U$: 应用边距后筛选出的正、负标签。</li>
</ul>
</li>
</ol>
<p>HBM损失被应用到两个基于单元的HTC模型中：</p>
<ol>
<li><strong>HPT模型</strong>：<ul>
<li>将每一层的标签视为一个单元。</li>
<li>训练和推断阶段使用相同的单元结构。</li>
</ul>
</li>
<li><strong>HiDEC模型</strong>：<ul>
<li>在训练阶段基于目标标签生成单元，而在推断阶段从根节点扩展子层次结构生成单元。</li>
</ul>
</li>
</ol>
<p>在这两种模型中，HBM只需要添加一个简单的前馈神经网络（Feedforward Neural Network, FFN）来学习单元的边界，参数开销较小。</p>
<p>每个文档 $x_d$​ 对应一个标签集合 $Y_d$​。标签按层次结构分组为单元 U。对于每个单元：</p>
<ul>
<li><strong>正标签集合$N_{pos}^U$​</strong>：包含在 $Y_d$​ 中的标签。</li>
<li>**负标签集合 $N_{neg}^U$**：不在 $Y_d$​ 中的标签。</li>
</ul>
<h4 id="HBM损失的具体过程"><a href="#HBM损失的具体过程" class="headerlink" title="HBM损失的具体过程"></a><strong>HBM损失的具体过程</strong></h4><ol>
<li><p><strong>边界的动态优化</strong>：</p>
<ul>
<li>使用单元表示 $r_U$​ 学习边界 $t_U$​，以便根据层次结构和文本特性，为每个单元预测不同的阈值。</li>
<li>在推断阶段，边界用于动态分类：$Y_d^U &#x3D; {v_i | l_{v_i}^U &gt; t_U, v_i \in U}$。</li>
</ul>
</li>
<li><p><strong>计算偏置</strong>：</p>
<ul>
<li>偏置根据正负标签的logits标准差计算：$g &#x3D; \alpha \cdot \text{std}({l_v^U | v \in N})$，其中 α\alphaα 是超参数。</li>
<li>偏置调整正标签的边界更高，负标签的边界更低，从而提高低置信度标签的重要性。</li>
</ul>
</li>
<li><p><strong>应用边距</strong>：</p>
<ul>
<li>将高置信度标签（例如 $\sigma(2(l_{v_i}^U - t_U)) &gt; 1 - m$ 的正标签）从训练损失中剔除，减少它们的影响。</li>
</ul>
</li>
</ol>
<h4 id="在模型中的实现"><a href="#在模型中的实现" class="headerlink" title="在模型中的实现"></a><strong>在模型中的实现</strong></h4><ul>
<li><strong>HPT模型</strong>：<ul>
<li>每个单元对应层次结构的同一层标签。</li>
</ul>
</li>
<li><strong>HiDEC模型</strong>：<ul>
<li>基于文档的目标标签，在训练和推断阶段分别动态生成子层次单元。</li>
</ul>
</li>
</ul>
<h1 id="Results-3"><a href="#Results-3" class="headerlink" title="Results"></a>Results</h1><ul>
<li>HBM损失在三个数据集（RCV1-v2, NYT, EURLEX57K）上的表现优于其他主流HTC模型（如HPT、HiDEC）。</li>
<li>对于大规模数据集EURLEX57K，HBM的改进效果最显著，说明它在解决标签不平衡问题上更有效。</li>
<li>消融实验表明，边界、偏置和边距三者的组合效果最佳。</li>
</ul>
<h1 id="Weakness-3"><a href="#Weakness-3" class="headerlink" title="Weakness"></a>Weakness</h1><ul>
<li><strong>额外参数需求</strong>：HBM引入了可学习边界，因此需要额外的参数来优化。</li>
<li><strong>边界泛化问题</strong>：在某些情况下，训练阶段学习到的边界可能在推断阶段表现不佳，尤其是针对某些特定标签。</li>
</ul>
<h1 id="5-Recommending-What-Video-to-Watch-Next-A-Multitask-Ranking-System"><a href="#5-Recommending-What-Video-to-Watch-Next-A-Multitask-Ranking-System" class="headerlink" title="5. Recommending What Video to Watch Next: A Multitask Ranking System"></a>5. Recommending What Video to Watch Next: A Multitask Ranking System</h1><h2 id="Motivation-4"><a href="#Motivation-4" class="headerlink" title="Motivation:"></a>Motivation:</h2><p>设计一个现实世界中可用的大规模视频推荐系统有很多挑战：有很多不同的、相冲突的优化目标；系统有很多隐式的偏差（用户点击和看一个视频只因为它的评分高，而不是因为它是用户喜欢的）；</p>
<h2 id="Methods："><a href="#Methods：" class="headerlink" title="Methods："></a>Methods：</h2><ol>
<li>把多项目标分类为两个类别：1）engagement（用户点击、推荐视频的点击程度），2）满意度，用户点赞一个视频然后留下一个评分。</li>
<li>用MMoE(Multi-gate Mixture-of-Experts)自动学习参数，在可能冲突的不同objectives之间分享信息。</li>
<li>MoE把输入模块化再输入experts，每个都关注输入的不同方面，这提升了从不同模态生成的复杂特征空间的学习的表示。</li>
<li>然后使用multiple gate网络，每个objectives可以选择experts去分享或不分享。</li>
<li>为了从有偏差的数据里建模和减少选择偏差，在主要模型上加一个shallow tower（例如由现有的系统决定排序，然后在最终预测上加一个范围作为bias term）</li>
<li>网络结构分解测试数据的label成为两个部分：（1）从主模型里学到的unbiased user utility（2）从shallow tower里学到的估计的预估倾向分数</li>
<li>提出的模型结构能看作一个Wide&amp;Deep model的扩展，其中shallow tower表示了Wide part。<br>总结：（1）引入一个end-to-end排序系统做视频推荐；（2）把排序问题想成multi-objective learning problem，扩展了MMoE结构，提升在所有objectives上的表现；（3） 在模型上应用Wide&amp;Deep model结构，缓和了position bias；（4）在真实世界的大规模视频推荐系统上评估了方法，有重大提升。<br>![[Pasted image 20241129094044.png]]<br>![[Pasted image 20241129104812.png]]<br>![[Pasted image 20241129104842.png]]<br>![[Pasted image 20241129095107.png]]<br>![[Pasted image 20241129095535.png]]<br>![[Pasted image 20241129104131.png]]</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2024/11/29/test/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Data-Mixing-Laws-Optimizing-Data-Mixtures-by-Predicting-Language-Modeling-Performance%EF%BC%88Data-Mixture%EF%BC%89"><span class="nav-number">1.</span> <span class="nav-text">1. Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance（Data Mixture）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation"><span class="nav-number">1.1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method"><span class="nav-number">1.2.</span> <span class="nav-text">Method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results"><span class="nav-number">1.3.</span> <span class="nav-text">Results</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Weakness"><span class="nav-number">1.4.</span> <span class="nav-text">Weakness</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-REGMIX-Data-Mixture-as-Regression-for-Language-Model-Pre-training-Data-Mixture"><span class="nav-number">2.</span> <span class="nav-text">2. REGMIX: Data Mixture as Regression for Language Model Pre-training(Data Mixture)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation-1"><span class="nav-number">2.1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods"><span class="nav-number">2.2.</span> <span class="nav-text">Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results-1"><span class="nav-number">2.3.</span> <span class="nav-text">Results</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Weakness-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">Weakness</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-SELP-A-Semantically-Driven-Approach-for-Separated-and-Accurate-Class-Prototypes-in-Few-Shot-Text-Classification"><span class="nav-number">3.</span> <span class="nav-text">3. SELP: A Semantically-Driven Approach for Separated and Accurate Class Prototypes in Few-Shot Text Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Meta-learning"><span class="nav-number">3.1.</span> <span class="nav-text">Meta-learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Meta-learning-%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">3.1.1.</span> <span class="nav-text">1. Meta-learning 的基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Meta-learning-%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86"><span class="nav-number">3.1.2.</span> <span class="nav-text">2. Meta-learning 的关键组成部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-Meta-learner"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">(1) Meta-learner</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Base-learner"><span class="nav-number">3.1.2.2.</span> <span class="nav-text">(2) Base-learner</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Task-Distribution"><span class="nav-number">3.1.2.3.</span> <span class="nav-text">(3) Task Distribution</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Meta-learning-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95"><span class="nav-number">3.1.3.</span> <span class="nav-text">3. Meta-learning 的主要方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%8C%96%E7%9A%84-Meta-learning"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">(1) 基于优化的 Meta-learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84-Meta-learning"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">(2) 基于模型的 Meta-learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%9F%BA%E4%BA%8E%E5%BA%A6%E9%87%8F%E7%9A%84-Meta-learning"><span class="nav-number">3.1.3.3.</span> <span class="nav-text">(3) 基于度量的 Meta-learning</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Meta-learning-%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">3.1.4.</span> <span class="nav-text">4. Meta-learning 的优势</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%BA%94%E7%94%A8%E4%BA%8E-Few-shot-Text-Classification-%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.1.5.</span> <span class="nav-text">5. 应用于 Few-shot Text Classification 的示例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Prototypical-Networks-%E7%A4%BA%E4%BE%8B"><span class="nav-number">3.1.5.1.</span> <span class="nav-text">Prototypical Networks 示例</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-Meta-learning-%E7%9A%84%E6%8C%91%E6%88%98"><span class="nav-number">3.1.6.</span> <span class="nav-text">6. Meta-learning 的挑战</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.1.7.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation-2"><span class="nav-number">3.2.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods-1"><span class="nav-number">3.3.</span> <span class="nav-text">Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results-2"><span class="nav-number">3.4.</span> <span class="nav-text">Results</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Weakness-2"><span class="nav-number">3.5.</span> <span class="nav-text">Weakness</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Hierarchy-aware-Biased-Bound-Margin-Loss-Function-for-Hierarchical-Text-Classification"><span class="nav-number">4.</span> <span class="nav-text">4. **Hierarchy-aware Biased Bound Margin Loss Function for Hierarchical Text Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation-3"><span class="nav-number">4.1.</span> <span class="nav-text">Motivation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Methods-2"><span class="nav-number">5.</span> <span class="nav-text">Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HBM%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"><span class="nav-number">5.0.0.1.</span> <span class="nav-text">HBM损失的具体过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.0.0.2.</span> <span class="nav-text">在模型中的实现</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Results-3"><span class="nav-number">6.</span> <span class="nav-text">Results</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Weakness-3"><span class="nav-number">7.</span> <span class="nav-text">Weakness</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Recommending-What-Video-to-Watch-Next-A-Multitask-Ranking-System"><span class="nav-number">8.</span> <span class="nav-text">5. Recommending What Video to Watch Next: A Multitask Ranking System</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation-4"><span class="nav-number">8.1.</span> <span class="nav-text">Motivation:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods%EF%BC%9A"><span class="nav-number">8.2.</span> <span class="nav-text">Methods：</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">DizzyHardSugar</p>
  <div class="site-description" itemprop="description">notes, thoughts</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DizzyHardSugar</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
